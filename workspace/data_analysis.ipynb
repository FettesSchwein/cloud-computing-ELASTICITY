{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "# Data Analysis\n",
    "\n",
    "Before you start, make sure that you are familiar with the basic usage of Jupyter Notebook. \n",
    "\n",
    "If not, please finish the Jupyter Notebook primer first. Within that primer you can find links to some starter notebooks hosted on Google Colab that will help you practice Linux, Bash, and Pandas fundamentals with **worked examples**.\n",
    "\n",
    "In this task, you need to implement the following methods:\n",
    "```\n",
    "load_data_to_series\n",
    "q6\n",
    "q7\n",
    "q8\n",
    "q9\n",
    "```\n",
    "\n",
    "Please implement the `load_data_to_series` method first. You can check the output for each question by executing the cell below the question.\n",
    "\n",
    "More cells may be added to the notebook. If you don't want to include the cell in the converted script, please tag the cell with `excluded_from_script`. You can display the tags for each cell in Jupyter Notebook: `View > Cell Toolbar > Tags`.\n",
    "\n",
    "Execute `./runner.sh` in the console to check the result. Please make sure that the virtualenv is activated when `runner.sh` runs.\n",
    "\n",
    "Finally, remember the write-up section regarding encoding awareness and ensure that you practice those concepts when completing the required questions within this notebook.\n",
    "\n",
    "# Pandas\n",
    "\n",
    "Pandas is a Python library for practical and real-world data analysis. It provides fast, flexible, and expressive data structures to make it easy to work with data. \n",
    "\n",
    "There are two primary data structures provided by Pandas, Series (1-dimensional) and DataFrame (2-dimensional). This week you will start with the Series. And you will practice with the DataFrame next week.\n",
    "\n",
    "# Series\n",
    "\n",
    "A Series is a one-dimensional labeled array that can hold any data type, integer, floating point number, Python objects, etc. In this task, you will load the filtered Wikipedia output into a Series, where the page title is the label and view count is the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_to_series(input_file):\n",
    "    \"\"\"\n",
    "    Load the input file into a Series.\n",
    "    Please read the documentation of the method `pandas.read_csv`:\n",
    "    https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html?highlight=index_col\n",
    "\n",
    "    The default behavior of read_csv will infer the column names using the first line of the input file.\n",
    "    In the provided Wikipedia dataset, the first line of the input file is not the column names; \n",
    "    hence, you need to change this default behavior.\n",
    "    \n",
    "    Hint: \n",
    "    1. How to read a TSV file using the read_csv method by specifying the delimiter\n",
    "    2. How to not infer the first line as the column names\n",
    "    3. How to read the data into a Series instead of a Dataframe\n",
    "    4. How to specify the column to be used as the row labels\n",
    "    \n",
    "    :param input_file: the path to the input file\n",
    "    :return: the Series\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Load the input_file in to a Series\n",
    "    df = pd.read_csv(input_file, sep='\\t', header=None, index_col=0)\n",
    "    series = df.iloc[:, 0]\n",
    "    \n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q6():\n",
    "    \"\"\"\n",
    "    Print a small sample of a Series as CSV\n",
    "    \n",
    "    To view the top n records, read the documentation:\n",
    "    https://pandas.pydata.org/pandas-docs/stable/basics.html#head-and-tail\n",
    "    \n",
    "    output format:\n",
    "    <page title>,<page view>\n",
    "    <page title>,<page view>\n",
    "    <page title>,<page view>\n",
    "    ...\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # read the output into series\n",
    "    series = load_data_to_series(\"output\")\n",
    "    \n",
    "    # TODO: replace \"None\" with your implementation to select the first 10 records\n",
    "    res=series.head(10)\n",
    "    \n",
    "    # print the result to standard output in the CSV format\n",
    "    res.to_csv(sys.stdout, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 917507, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mParserError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mq6\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mq6\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mPrint a small sample of a Series as CSV\u001b[39;00m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     13\u001b[39m \n\u001b[32m     14\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# read the output into series\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m series = \u001b[43mload_data_to_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# TODO: replace \"None\" with your implementation to select the first 10 records\u001b[39;00m\n\u001b[32m     20\u001b[39m res=series.head(\u001b[32m10\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mload_data_to_series\u001b[39m\u001b[34m(input_file)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03mLoad the input file into a Series.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03mPlease read the documentation of the method `pandas.read_csv`:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     18\u001b[39m \u001b[33;03m:return: the Series\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# TODO: Load the input_file in to a Series\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m series = df.iloc[:, \u001b[32m0\u001b[39m]\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m series\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rjsli\\anaconda3\\envs\\ml601\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rjsli\\anaconda3\\envs\\ml601\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rjsli\\anaconda3\\envs\\ml601\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rjsli\\anaconda3\\envs\\ml601\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:838\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:905\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:874\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:891\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2061\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mParserError\u001b[39m: Error tokenizing data. C error: Expected 1 fields in line 917507, saw 4\n"
     ]
    }
   ],
   "source": [
    "q6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q7():\n",
    "    \"\"\"\n",
    "    Get values by index label\n",
    "    \n",
    "    Since the page title is the label of the Series, you can get the page view by page title.\n",
    "    Please read the documentation:\n",
    "    https://pandas.pydata.org/pandas-docs/stable/dsintro.html#series-is-dict-like\n",
    "    \n",
    "    output format:\n",
    "    <page view>\n",
    "    \"\"\"\n",
    "    \n",
    "    # read the output into a Series \n",
    "    series = load_data_to_series(\"output\")\n",
    "    res = series[\"Cloud_computing\"]\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "q7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q8():\n",
    "    \"\"\"\n",
    "    Generates descriptive statistics of a Series\n",
    "    \n",
    "    Please read the documentation of the Series and find the method to show all the descriptive statistics.\n",
    "    https://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.html?highlight=descriptive\n",
    "    \n",
    "    output format:\n",
    "    \n",
    "    count,<number>\n",
    "    mean,<number>\n",
    "    std,<number>\n",
    "    min,<number>\n",
    "    25%,<number>\n",
    "    50%,<number>\n",
    "    75%,<number>\n",
    "    max,<number>\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # read the output into a Series\n",
    "    series = load_data_to_series(\"output\")\n",
    "    res = series.describe()\n",
    "    res.to_csv(sys.stdout, encoding='utf-8', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "q8()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q9():\n",
    "    \"\"\"\n",
    "    Data filtering in Series\n",
    "    \n",
    "    Boolean indexing can be used to filtering data in a Series.\n",
    "    https://pandas.pydata.org/pandas-docs/stable/indexing.html#boolean-indexing\n",
    "    \n",
    "    output format:\n",
    "    <page title>,<page view>\n",
    "    <page title>,<page view>\n",
    "    <page title>,<page view>\n",
    "    ...\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # read the output into a Series\n",
    "    series = load_data_to_series(\"output\")\n",
    "    res = series[(series >= 2000) & (series < 3000)]\n",
    "    res.to_csv(sys.stdout, encoding='utf-8', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "outputs": [],
   "source": [
    "q9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "excluded_from_script"
    ]
   },
   "source": [
    "# DO NOT MODIFY ANYTHING BELOW  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(\n",
    "    description=\"Data Analysis\")\n",
    "    parser.add_argument(\"-r\",\n",
    "                        metavar='<question_id>',\n",
    "                        required=False)\n",
    "    args = parser.parse_args()\n",
    "    question = args.r\n",
    "\n",
    "    if question is None:\n",
    "        q6()\n",
    "        q7()\n",
    "        q8()\n",
    "        q9()\n",
    "    elif question == \"q6\":\n",
    "        q6()\n",
    "    elif question == \"q7\":\n",
    "        q7()\n",
    "    elif question == \"q8\":\n",
    "        q8()\n",
    "    elif question == \"q9\":\n",
    "        q9()\n",
    "    else:\n",
    "        print(\"Invalid question\")\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "ml601",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
